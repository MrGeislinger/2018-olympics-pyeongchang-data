{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import csv\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "I'm scraping the data from https://www.olympic.org/ via BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful references to directories (all directories end with '/')\n",
    "#TODO -> change to 'en/' and change references to connector\n",
    "dr_connector = 'en/'\n",
    "dr_imgs = 'resOWG2018/img/'\n",
    "dr_results = 'https://www.olympic.org/pyeongchang-2018/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sports & Events Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to list of all sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule page has reference to all sports in table\n",
    "url_schedule = 'https://www.olympic.org/pyeongchang-2018/results/en/general/competition-schedule.htm'\n",
    "\n",
    "# Get document to be passed in for soup (better/cleaner practice)\n",
    "request_schedule = requests.get(url_schedule)\n",
    "text_schedule = request_schedule.text\n",
    "\n",
    "# Get all sports from schedule page\n",
    "soup_schedule = BeautifulSoup(text_schedule, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image container and the name/link container (comes in pairs)\n",
    "sports = soup_schedule.find_all('td', {'class':['disciplinePicture', 'styleLeft']})\n",
    "\n",
    "# Dictonary for the sports\n",
    "sports_info = []\n",
    "\n",
    "# Go every other since it always matches to one sport\n",
    "for img, name in zip(sports[::2], sports[1::2]):\n",
    "    \n",
    "    # Skip for the ceremony image (and other errors)\n",
    "    if name.a == None:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Get the image link which has the sports ID \n",
    "    # form: ../../resOWG2018/img/sports/CER.png\n",
    "    sport_img_link = img.img['src']\n",
    "    \n",
    "    # Get ID from link\n",
    "    match = re.search('(\\w+)\\.png$', sport_img_link)\n",
    "    sport_id = match.group(1)\n",
    "    \n",
    "    # Get image as a link\n",
    "    sport_img = '{}{}sports/{}.png'.format(dr_results, dr_imgs, sport_id)\n",
    "    \n",
    "    \n",
    "    # Get sport's schedule page\n",
    "    match = re.search('(([-\\w]+)\\/daily-schedule.htm)$', name.a['href'])    \n",
    "    sport_schedule = '{}{}{}'.format(dr_results, dr_connector, match.group(1))\n",
    "\n",
    "    # Get sport's full name from link (words separated by -)\n",
    "    sport_name = match.group(2)\n",
    "    \n",
    "    sport_dict = {'code_id': sport_id, 'img': sport_img, 'schedule': sport_schedule, 'name': sport_name}\n",
    "    sports_info.append(sport_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "print(len(sports_info))\n",
    "\n",
    "for sport in sports_info:\n",
    "    for k, v in sport.items():\n",
    "        print(k,v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to sports' different events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each sport, get the different events\n",
    "for sport in sports_info:\n",
    "    sport_name = sport['name']\n",
    "    \n",
    "    # Get HTML text from sport's list of events\n",
    "    url_event = '{}{}{}/sport-entries.htm'.format(dr_results, dr_connector, sport_name)\n",
    "    request_event = requests.get(url_event)\n",
    "    text_event = request_event.text\n",
    "    soup_event = BeautifulSoup(text_event, 'html.parser')\n",
    "    \n",
    "    # Look for all events for this sport\n",
    "    events = soup_event.find_all('li', class_='entriesByEventElem')\n",
    "    \n",
    "    # Save all event info into a list of events for the sport\n",
    "    events_info = []\n",
    "    for event in events:\n",
    "        \n",
    "        # Get info from event page\n",
    "        event_page_link = event.a['href']\n",
    "        match = re.search('\\/(entries-by-event-([\\w-]*)\\.htm)$', event_page_link)\n",
    "        \n",
    "        # Get the web page for the event \n",
    "        event_page = '{}{}{}{}'.format(dr_results, dr_connector, sport_name, match.group(1))\n",
    "        event_name = match.group(2)\n",
    "        \n",
    "        # Get sex by seeing if it's men's, women's, or mixed\n",
    "        sex_categories = ('men', 'women')\n",
    "        # Default to mixed event\n",
    "        event_sex = 'mixed'\n",
    "        for sex in sex_categories:\n",
    "            # Save sex then breakout of loop if found\n",
    "            if sex in event_name:\n",
    "                event_sex = sex\n",
    "                break\n",
    "                        \n",
    "        # Process name so it is easier for reading\n",
    "        event_readable = event.a.text.strip().lower()\n",
    "         \n",
    "        \n",
    "        # Save event info into list of events (for this sport)\n",
    "        event_info = {'name': event_name, 'sex': event_sex, 'readable_name': event_readable, 'page': event_page}\n",
    "        events_info.append(event_info)\n",
    "        \n",
    "    # Save list of events in sport_info\n",
    "    sport['events'] = events_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for events\n",
    "sports_info[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save sports data into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV file from list of sports dictionaries\n",
    "with open('sports.csv', 'w') as sports_csv:\n",
    "    writer = csv.writer(sports_csv)\n",
    "    \n",
    "    # Headers\n",
    "    headers = ['code_id', 'name', 'img', 'schedule']\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Get each dictionary assoc. with the sport\n",
    "    for sport in sports_info:\n",
    "        # Use only the headers (in order) to write row \n",
    "        row = [sport[key] for key in headers]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Country Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to list of all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_countries = 'https://www.olympic.org/pyeongchang-2018/results/en/general/nocs-list.htm'\n",
    "\n",
    "# Get document to be passed in for soup (better/cleaner practice)\n",
    "request_countries = requests.get(url_list_countries)\n",
    "text_countires = request_countries.text\n",
    "\n",
    "# Get all countries from main page\n",
    "soup_countries = BeautifulSoup(text_countires, 'html.parser')\n",
    "countries = soup_countries.find_all('div', class_='CountriesListItem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country pages, flags, IDs, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries of countries info \n",
    "countries_info = []\n",
    "\n",
    "# Iterate over countries and save info\n",
    "for country in countries:\n",
    "    # Country code gives an identifier of 3 character\n",
    "    country_id = country['attrcountrycode']\n",
    "\n",
    "    # Country web page\n",
    "    country_page_link = country.a['href']\n",
    "    match = re.search('\\/(noc-entries-([-\\w]+)\\.htm)$',country_page_link)\n",
    "    # group(1) form: noc-entries-country.htm\n",
    "    country_page = '{}{}general/{}'.format(dr_results, dr_connector, match.group(1))\n",
    "    \n",
    "    # Country full name\n",
    "    country_name = match.group(2) \n",
    "\n",
    "    # Flag image =>\n",
    "    country_flag = '{}resCOMMON/img/flags/{}.png'.format(dr_results,country_id)\n",
    "    \n",
    "    # Create a dictionary to be saved\n",
    "    country_dict = {'code_id':country_id, 'name':country_name, 'page':country_page, 'flag':country_flag}\n",
    "    countries_info.append(country_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "print(len(countries_info))\n",
    "\n",
    "\n",
    "for key, info in countries_info[0].items():\n",
    "    print(key, info)\n",
    "print()\n",
    "for key, info in countries_info[-1].items():\n",
    "    print(key, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save country data into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV file from list of countries dictionaries\n",
    "with open('countries.csv', 'w') as countries_csv:\n",
    "    writer = csv.writer(countries_csv)\n",
    "    \n",
    "    # Headers\n",
    "    headers = ['code_id', 'name', 'flag', 'page']\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Get each dictionary assoc. with the sport\n",
    "    for country in countries_info:\n",
    "        # Use only the headers (in order) to write row \n",
    "        row = [country[key] for key in headers]\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
