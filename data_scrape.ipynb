{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BSoup\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "I'm scraping the data from https://www.olympic.org/ via BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base is used to reference complete urls\n",
    "url_base = 'https://www.olympic.org'\n",
    "# Main page has reference to all sports (links & image representations)\n",
    "url_main = 'https://www.olympic.org/pyeongchang-2018'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sports & Event Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to list all sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document to be passed in for soup (better/cleaner practice)\n",
    "request_main = requests.get(url_main)\n",
    "text_main = request_main.text\n",
    "soup_main = BSoup(text_main, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image container and the name/link container (comes in pairs)\n",
    "sports_section = soup_main.find_all('section', {'class':'game-results-box'})[0]\n",
    "sports_section = sports_section.find_all('ul', {'class':['countries','games2018-2']})[0]\n",
    "sports_list = sports_section.find_all('li', {'class':'box'})\n",
    "\n",
    "# Dictonary for the sports\n",
    "sports_info = []\n",
    "for item in sports_list:\n",
    "    sport_name = item.a.text.strip()\n",
    "    # Link has full url address\n",
    "    sport_link = '{base}{sport}'.format(base=url_base, sport=item.a['href'])\n",
    "    # ID for sport will be what is used by website to define the sport's pages\n",
    "    sport_id = sport_name.lower().replace(' ','-')    \n",
    "    # Save each sport into list of dictionary info\n",
    "    sport_dict = {'id': sport_id, 'page': sport_link, 'name': sport_name}\n",
    "    sports_info.append(sport_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "print('Number of sports: {}'.format(len(sports_info)))\n",
    "print('====================')\n",
    "for sport in sports_info:\n",
    "    for k, v in sport.items():\n",
    "        print(k,v)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference to events in each sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sport, get the different events\n",
    "# Save all event info into a list of events for the sport\n",
    "events_info = []\n",
    "\n",
    "for sport in sports_info:\n",
    "    # Get document to be passed in for soup (better/cleaner practice)\n",
    "    request_sport = requests.get(sport['page'])\n",
    "    soup_main = BSoup(request_sport.text, 'html.parser')\n",
    "    \n",
    "    # Find the main section for all events in sports\n",
    "    main_section = soup_main.find_all('div', {'class':'main-holder'})[0]\n",
    "    # Find the event sections on this main page\n",
    "    event_sections = main_section.find_all('section', {'class':'event-box'})\n",
    "    # Get the event names & info for each event section\n",
    "    for event in event_sections:\n",
    "        name = event.a.text.strip()\n",
    "        page = '{base}{link}'.format(base=url_base, link=event.a['href'])\n",
    "        # The ID is the sport & the name used for webpage ref for event \n",
    "        # We trade brevity for ambiguity in the ID naming convention\n",
    "        event_id = re.search('[^/]+$', event.a['href']).group()\n",
    "        event_id = '{sport}-{event}'.format(sport=sport['id'], event=event_id)\n",
    "        \n",
    "        # Get sex by seeing if it's men's, women's, or mixed (definitions checked)\n",
    "        sex_categories = {'mixed':'mixed', 'gundersen':'men', 'man':'men', 'men':'men', \n",
    "                          'mens':'men', 'women':'women', 'womens':'women', 'ladies':'women'}\n",
    "        # Default to mixed event\n",
    "        event_sex = 'mixed'\n",
    "        is_assigned = False\n",
    "        # Loop over each category (time consuming but necessary)\n",
    "        for sex in sex_categories.keys():\n",
    "            \n",
    "            # Check if any of the words is the sex-term\n",
    "            if sex in event_id.split('-'):\n",
    "                # If there was more than one label applied, it's a mixed event \n",
    "                if is_assigned:\n",
    "                    event_sex = 'mixed'\n",
    "                    break\n",
    "                \n",
    "                event_sex = sex_categories[sex]\n",
    "                is_assigned = True       \n",
    "\n",
    "        \n",
    "        \n",
    "        # Save list of info dictionary for each event\n",
    "        event_dict = {'id': event_id, 'name': name, 'sport_id':sport['id'], 'sex':event_sex, 'page': page}\n",
    "        events_info.append(event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "print('Number of events: {}'.format(len(events_info)))\n",
    "print('====================')\n",
    "for event in random.choices(events_info, k=5):\n",
    "    for k, v in event.items():\n",
    "        print(k,v)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference to results for each event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "team_events = []\n",
    "# Replace ranking for Gold, Silver, Bronze, and no ranking (-1)\n",
    "medal_ranks = {'G':1, 'S':2, 'B':3}\n",
    "for event in events_info:\n",
    "    # Get document to be passed in for soup (better/cleaner practice)\n",
    "    request_event = requests.get(event['page'])\n",
    "    soup_results = BSoup(request_event.text, 'html.parser')\n",
    "    # Find the main section and table for all events in sports\n",
    "    try:\n",
    "        results_section = soup_results.find_all('section', {'class':'table-box'})[0]\n",
    "    except:\n",
    "        print('No results found: {}'.format(event['page']))\n",
    "    results_table = results_section.find_all('table')[0]\n",
    "    # Get the headers for the results\n",
    "    headers = results_table.find('thead')\n",
    "    result_headers = [h.text for h in headers.find_all('th')]\n",
    "    # If team event, save to do different processing\n",
    "    if 'team' in result_headers:\n",
    "        team_events.append(event)\n",
    "        continue\n",
    "    # Get the results\n",
    "    competitors = results_table.find('tbody')\n",
    "    # Ignore team events' with special tier in tbody\n",
    "    competitors = competitors.find_all('tr', {'class': None})\n",
    "    # Each competitor (can be a team) has a result line\n",
    "    competitors_info = []\n",
    "    for c in competitors:\n",
    "        # Get competition info from each tier\n",
    "        c_dict = {}\n",
    "        c = c.find_all('td')\n",
    "        # Save the competitor and remove extra new lines (was used on website formatting)\n",
    "        c_dict = {h: cc.text.strip().replace('\\n','').replace('\\r','') for h,cc in zip(result_headers,c)}\n",
    "        # Replace rank as number (integers)\n",
    "        ranking = c_dict.get('Rank')\n",
    "        try:\n",
    "            # Get the integer rank if there is a decimal\n",
    "            c_dict['Rank'] = int(ranking.split('.')[0])\n",
    "        # If not a number either a medalist or something else (no ranking)\n",
    "        except: \n",
    "            # -1 means no obvious ranking\n",
    "            c_dict['Rank'] = medal_ranks.get(ranking, -1) \n",
    "        competitors_info.append(c_dict)\n",
    "    # Save all event results into one dictionary\n",
    "    results[event['id']] = competitors_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "# print(results.keys())\n",
    "# [print(r) for r in results['alpine-skiing-mens-downhill']]\n",
    "for r,dicts in results.items():\n",
    "    print(r)\n",
    "    print(dicts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data into CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sports Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV file from list of sports dictionaries\n",
    "with open('data/sports.csv', 'w') as sports_csv:\n",
    "    writer = csv.writer(sports_csv)\n",
    "    \n",
    "    # Headers\n",
    "    headers = ['id', 'name', 'page']\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Get each dictionary assoc. with the sport\n",
    "    for sport in sports_info:\n",
    "        # Use only the headers (in order) to write row \n",
    "        row = [sport[key] for key in headers]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV file from list of events dictionaries\n",
    "with open('data/events.csv', 'w') as events_csv:\n",
    "    writer = csv.writer(events_csv)\n",
    "    \n",
    "    # Headers\n",
    "    headers = ['id', 'name', 'sport_id', 'sex', 'page']\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Get each dictionary assoc. with the sport\n",
    "    for event in events_info:\n",
    "        # Use only the headers (in order) to write row \n",
    "        row = [event[key] for key in headers]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header w/ event in front\n",
    "result_headers.insert(0, 'event')\n",
    "# Create CSV file from list of events dictionaries\n",
    "with open('data/results.csv', 'w') as results_csv:\n",
    "    writer = csv.writer(results_csv)\n",
    "    writer.writerow(result_headers)\n",
    "    # Get each dictionary assoc. with each event\n",
    "    for event,event_results in results.items():\n",
    "        # Iterate over each result of event\n",
    "        for result in event_results:\n",
    "            # Use only the headers (in order) to write row \n",
    "            row = [result.get(key) for key in result_headers[1:]]\n",
    "            row.insert(0,event)\n",
    "            writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
