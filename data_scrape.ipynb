{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "I'm scraping the data from https://www.olympic.org/ via BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful references to directories (all directories end with '/')\n",
    "#TODO -> change to 'en/' and change references to connector\n",
    "dr_connector = 'en/general/'\n",
    "dr_imgs = 'resOWG2018/img/'\n",
    "dr_results = 'https://www.olympic.org/pyeongchang-2018/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to list of all sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule page has reference to all sports in table\n",
    "url_schedule = 'https://www.olympic.org/pyeongchang-2018/results/en/general/competition-schedule.htm'\n",
    "\n",
    "# Get document to be passed in for soup (better/cleaner practice)\n",
    "request_schedule = requests.get(url_schedule)\n",
    "text_schedule = request_schedule.text\n",
    "\n",
    "# Get all sports from schedule page\n",
    "soup_schedule = BeautifulSoup(text_schedule, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image container and the name/link container (comes in pairs)\n",
    "sports = soup_schedule.find_all('td', {'class':['disciplinePicture', 'styleLeft']})\n",
    "\n",
    "# Dictonary for the sports\n",
    "sports_info = {}\n",
    "\n",
    "# Go every other since it always matches to one sport\n",
    "for img, name in zip(sports[::2], sports[1::2]):\n",
    "    \n",
    "    # Skip for the ceremony image (and other errors)\n",
    "    if name.a == None:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Get the image link which has the sports ID \n",
    "    # form: ../../resOWG2018/img/sports/CER.png\n",
    "    sport_img_link = img.img['src']\n",
    "    \n",
    "    # Get ID from link\n",
    "    match = re.search('(\\w+)\\.png$', sport_img_link)\n",
    "    sport_id = match.group(1)\n",
    "    \n",
    "    # Get image as a link\n",
    "    sport_img = '{}{}sports/{}.png'.format(dr_results, dr_imgs, sport_id)\n",
    "    \n",
    "    \n",
    "    # Get sport's schedule page\n",
    "    match = re.search('(([-\\w]+)\\/daily-schedule.htm)$', name.a['href'])    \n",
    "    sport_schedule = '{}en/{}'.format(dr_results, match.group(1))\n",
    "\n",
    "    # Get sport's full name from link (words separated by -)\n",
    "    sport_name = match.group(2)\n",
    "    \n",
    "          \n",
    "    sports_info[sport_id] = {'img': sport_img, 'schedule': sport_schedule, 'name': sport_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "print(len(sports_info))\n",
    "\n",
    "for key, sport in sports_info.items():\n",
    "    print(key)\n",
    "    for k,v in sport.items():\n",
    "        print(k, v)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Country Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to list of all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_countries = 'https://www.olympic.org/pyeongchang-2018/results/en/general/nocs-list.htm'\n",
    "\n",
    "# Get document to be passed in for soup (better/cleaner practice)\n",
    "request_countries = requests.get(url_list_countries)\n",
    "text_countires = request_countries.text\n",
    "\n",
    "# Get all countries from main page\n",
    "soup_countries = BeautifulSoup(text_countires, 'html.parser')\n",
    "countries = soup_countries.find_all('div', class_='CountriesListItem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country pages, flags, IDs, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary\n",
    "countries_info = {}\n",
    "\n",
    "# Iterate over countries and save info\n",
    "for country in countries:\n",
    "    # Country code gives an identifier of 3 character\n",
    "    country_id = country['attrcountrycode']\n",
    "\n",
    "    # Country web page\n",
    "    country_page_link = country.a['href']\n",
    "    match = re.search('\\/([\\w-]+-(\\w+)\\.htm)$',country_page_link)\n",
    "    # group(1) form: noc-entries-country.htm\n",
    "    country_page = '{}{}{}'.format(dr_results, dr_connector, match.group(1))\n",
    "    \n",
    "    # Country full name\n",
    "    country_name = match.group(2) \n",
    "\n",
    "    # Flag image =>\n",
    "    country_flag = '{}resCOMMON/img/flags/{}.png'.format(dr_results,country_id)\n",
    "    \n",
    "    countries_info[country_id] = {'name':country_name, 'page':country_page, 'flag':country_flag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "print(len(countries_info))\n",
    "print(countries_info['USA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
