{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BSoup\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "I'm scraping the data from https://www.olympic.org/ via BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base is used to reference complete urls\n",
    "url_base = 'https://www.olympic.org'\n",
    "# Main page has reference to all sports (links & image representations)\n",
    "url_main = 'https://www.olympic.org/pyeongchang-2018'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sports & Event Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to list all sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document to be passed in for soup (better/cleaner practice)\n",
    "request_main = requests.get(url_main)\n",
    "text_main = request_main.text\n",
    "soup_main = BSoup(text_main, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image container and the name/link container (comes in pairs)\n",
    "sports_section = soup_main.find_all('section', {'class':'game-results-box'})[0]\n",
    "sports_section = sports_section.find_all('ul', {'class':['countries','games2018-2']})[0]\n",
    "sports_list = sports_section.find_all('li', {'class':'box'})\n",
    "\n",
    "# Dictonary for the sports\n",
    "sports_info = []\n",
    "for item in sports_list:\n",
    "    sport_name = item.a.text.strip()\n",
    "    # Link has full url address\n",
    "    sport_link = '{base}{sport}'.format(base=url_base, sport=item.a['href'])\n",
    "    # ID for sport will be what is used by website to define the sport's pages\n",
    "    sport_id = sport_name.lower().replace(' ','-')    \n",
    "    # Save each sport into list of dictionary info\n",
    "    sport_dict = {'id': sport_id, 'page': sport_link, 'name': sport_name}\n",
    "    sports_info.append(sport_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "print('Number of sports: {}'.format(len(sports_info)))\n",
    "print('====================')\n",
    "for sport in sports_info:\n",
    "    for k, v in sport.items():\n",
    "        print(k,v)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference to events in each sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sport, get the different events\n",
    "# Save all event info into a list of events for the sport\n",
    "events_info = []\n",
    "\n",
    "for sport in sports_info:\n",
    "    # Get document to be passed in for soup (better/cleaner practice)\n",
    "    request_sport = requests.get(sport['page'])\n",
    "    soup_main = BSoup(request_sport.text, 'html.parser')\n",
    "    \n",
    "    # Find the main section for all events in sports\n",
    "    main_section = soup_main.find_all('div', {'class':'main-holder'})[0]\n",
    "    # Find the event sections on this main page\n",
    "    event_sections = main_section.find_all('section', {'class':'event-box'})\n",
    "    # Get the event names & info for each event section\n",
    "    for event in event_sections:\n",
    "        name = event.a.text.strip()\n",
    "        page = '{base}{link}'.format(base=url_base, link=event.a['href'])\n",
    "        # The ID is the sport & the name used for webpage ref for event \n",
    "        # We trade brevity for ambiguity in the ID naming convention\n",
    "        event_id = re.search('[^/]+$', event.a['href']).group()\n",
    "        event_id = '{sport}-{event}'.format(sport=sport['id'], event=event_id)\n",
    "        # Save list of info dictionary for each event\n",
    "        event_dict = {'id': event_id, 'name': name, 'sport_id':sport['id'], 'page': page}\n",
    "        events_info.append(event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "print('Number of events: {}'.format(len(events_info)))\n",
    "print('====================')\n",
    "for event in random.choices(events_info, k=5):\n",
    "    for k, v in event.items():\n",
    "        print(k,v)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data into CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sports Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV file from list of sports dictionaries\n",
    "with open('sports.csv', 'w') as sports_csv:\n",
    "    writer = csv.writer(sports_csv)\n",
    "    \n",
    "    # Headers\n",
    "    headers = ['id', 'name', 'page']\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Get each dictionary assoc. with the sport\n",
    "    for sport in sports_info:\n",
    "        # Use only the headers (in order) to write row \n",
    "        row = [sport[key] for key in headers]\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
