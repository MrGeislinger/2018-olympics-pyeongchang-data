{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import csv\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "I'm scraping the data from https://www.olympic.org/ via BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful references to directories (all directories end with '/')\n",
    "dr_connector = 'en/'\n",
    "dr_imgs = 'resOWG2018/img/'\n",
    "dr_results = 'https://www.olympic.org/pyeongchang-2018/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sports & Events Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to list of all sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schedule page has reference to all sports in table\n",
    "url_schedule = 'https://www.olympic.org/pyeongchang-2018/results/en/general/competition-schedule.htm'\n",
    "\n",
    "# Get document to be passed in for soup (better/cleaner practice)\n",
    "request_schedule = requests.get(url_schedule)\n",
    "text_schedule = request_schedule.text\n",
    "\n",
    "# Get all sports from schedule page\n",
    "soup_schedule = BeautifulSoup(text_schedule, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image container and the name/link container (comes in pairs)\n",
    "sports = soup_schedule.find_all('td', {'class':['disciplinePicture', 'styleLeft']})\n",
    "\n",
    "# Dictonary for the sports\n",
    "sports_info = []\n",
    "\n",
    "# Go every other since it always matches to one sport\n",
    "for img, name in zip(sports[::2], sports[1::2]):\n",
    "    \n",
    "    # Skip for the ceremony image (and other errors)\n",
    "    if name.a == None:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Get the image link which has the sports ID \n",
    "    # form: ../../resOWG2018/img/sports/CER.png\n",
    "    sport_img_link = img.img['src']\n",
    "    \n",
    "    # Get ID from link\n",
    "    match = re.search('(\\w+)\\.png$', sport_img_link)\n",
    "    sport_id = match.group(1)\n",
    "    \n",
    "    # Get image as a link\n",
    "    sport_img = '{}{}sports/{}.png'.format(dr_results, dr_imgs, sport_id)\n",
    "    \n",
    "    \n",
    "    # Get sport's schedule page\n",
    "    match = re.search('(([-\\w]+)\\/daily-schedule.htm)$', name.a['href'])    \n",
    "    sport_schedule = '{}{}{}'.format(dr_results, dr_connector, match.group(1))\n",
    "\n",
    "    # Get sport's full name from link (words separated by -)\n",
    "    sport_name = match.group(2)\n",
    "    \n",
    "    sport_dict = {'id': sport_id, 'img': sport_img, 'schedule': sport_schedule, 'name': sport_name}\n",
    "    sports_info.append(sport_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "print(len(sports_info))\n",
    "\n",
    "for sport in sports_info:\n",
    "    for k, v in sport.items():\n",
    "        print(k,v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to sports' different events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each sport, get the different events\n",
    "# Save all event info into a list of events for the sport\n",
    "events_info = []\n",
    "\n",
    "for sport in sports_info:\n",
    "    sport_id = sport['id']\n",
    "    sport_name = sport['name']\n",
    "    \n",
    "    # Get HTML text from sport's list of events\n",
    "    url_event = '{}{}{}/sport-entries.htm'.format(dr_results, dr_connector, sport_name)\n",
    "    request_event = requests.get(url_event)\n",
    "    text_event = request_event.text\n",
    "    soup_event = BeautifulSoup(text_event, 'html.parser')\n",
    "    \n",
    "    # Look for all events for this sport\n",
    "    events = soup_event.find_all('li', class_='entriesByEventElem')\n",
    "    \n",
    "\n",
    "    for event in events:\n",
    "        \n",
    "        # Get info from event page\n",
    "        event_page_link = event.a['href']\n",
    "        match = re.search('\\/(entries-by-event-([\\w-]*)\\.htm)$', event_page_link)\n",
    "        \n",
    "        # Get the web page for the event \n",
    "        event_page = '{}{}{}/{}'.format(dr_results, dr_connector, sport_name, match.group(1))\n",
    "        event_name = match.group(2)\n",
    "        \n",
    "        # Process name so it is easier for reading\n",
    "        event_readable = event.a.text.strip().lower()\n",
    "        \n",
    "        # Get sex by seeing if it's men's, women's, or mixed (definitions checked)\n",
    "        sex_categories = {'mixed':'mixed', 'gundersen':'men', 'man':'men', 'men':'men', 'women':'women', 'ladies':'women'}\n",
    "        # Default to mixed event\n",
    "        event_sex = 'mixed'\n",
    "        is_assigned = False\n",
    "        # Loop over each category (time consuming but necessary)\n",
    "        for sex in sex_categories.keys():\n",
    "            \n",
    "            \n",
    "            # Check if any of the words is the sex-term\n",
    "            if sex in event_name.split('-'):\n",
    "                # If there was more than one label applied, it's a mixed event \n",
    "                if is_assigned:\n",
    "                    event_sex = 'mixed'\n",
    "                    break\n",
    "                \n",
    "                event_sex = sex_categories[sex]\n",
    "                is_assigned = True\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        # Save event info into list of events (for this sport)\n",
    "        event_info = {'name': event_name, 'sport_id':sport_id, 'sex': event_sex, 'readable_name': event_readable, 'page': event_page}\n",
    "        events_info.append(event_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for events\n",
    "len(events_info)\n",
    "for i in range(5):\n",
    "    for k,v in events_info[i].items():\n",
    "        print(k,v)\n",
    "    print()\n",
    "\n",
    "# for e in events_info:\n",
    "#     print(e['sex'],e['name'])\n",
    "#     print(e['page'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference events' pages to get athlete info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better to make this a constant outsided of method (reusing this)\n",
    "convert_month_to_number = {\n",
    "    'Jan': '01',\n",
    "    'Feb': '02',\n",
    "    'Mar': '03',\n",
    "    'Apr': '04',\n",
    "    'May': '05',\n",
    "    'Jun': '06',\n",
    "    'Jul': '07',\n",
    "    'Aug': '08',\n",
    "    'Sep': '09',\n",
    "    'Oct': '10',\n",
    "    'Nov': '11',\n",
    "    'Dec': '12' \n",
    "}\n",
    "\n",
    "def get_athlete_profile_info(athlete_profile_page):\n",
    "    # Return a dictionary of other info\n",
    "    info = {}\n",
    "    \n",
    "    ## Get document to be passed in for soup (better/cleaner practice)\n",
    "    request_profile = requests.get(athlete_profile_page)\n",
    "    text_profile = request_profile.text\n",
    "    soup_profile = BeautifulSoup(text_profile, 'html.parser')\n",
    "    \n",
    "\n",
    "    # Get birthdate\n",
    "    quick_info_div = soup_profile.body.findAll(text=re.compile('Birth Date:'), limit=1)[0].parent.parent\n",
    "    birthdate_text = quick_info_div.text\n",
    "    match = re.search('(\\d{1,2}) (\\w+) (\\d{4})', birthdate_text)\n",
    "\n",
    "    # Day will be two digit number\n",
    "    info['birth_day'] =  match.group(1)\n",
    "    # Change month text to two digit number\n",
    "    info['birth_month'] = convert_month_to_number[match.group(2)]\n",
    "    info['birth_year'] = match.group(3)\n",
    "    \n",
    "    return(info)\n",
    "    \n",
    "    \n",
    "\n",
    "# Create a way to pull data from athlete's div\n",
    "def get_athlete_info(athlete_div):\n",
    "    # Country is 3 country code\n",
    "    athlete_country = athlete_div['attrcountrycode']\n",
    "\n",
    "    # picture is within another div\n",
    "    athlete_photo_div = athlete_div.find_all('div', class_='playerTagContainerPhoto')[0]\n",
    "    athlete_photo = athlete_photo_div.img['src']\n",
    "    # Create URL for photo\n",
    "    match = re.search('\\.\\./\\.\\./(.*)$', athlete_photo)\n",
    "    athlete_photo = match.group(1)\n",
    "    athlete_photo = '{}{}'.format(dr_results, athlete_photo)\n",
    "\n",
    "    # ID is numbers from picture name\n",
    "    athlete_id = re.search('\\/(\\d+)\\..*$', athlete_photo).group(1)\n",
    "\n",
    "    # name & link to profile\n",
    "    athlete_profile_link = athlete_div.find_all('div', class_='nameLine')[0].a\n",
    "    athlete_name = athlete_profile_link.text.lower()\n",
    "\n",
    "    # Create URL for profile page\n",
    "    match = re.search('\\.\\./\\.\\./en/(.*)$', athlete_profile_link['href'])\n",
    "    athlete_page = match.group(1)\n",
    "    athlete_page = '{}{}{}'.format(dr_results, dr_connector, athlete_page)\n",
    "    \n",
    "    \n",
    "    # Create dictionary for athlete\n",
    "    athlete_dict = {\n",
    "        'id':athlete_id, \n",
    "        'name':athlete_name, \n",
    "        'country_id':athlete_country, \n",
    "        'photo':athlete_photo, \n",
    "        'profile':athlete_page\n",
    "    }\n",
    "    \n",
    "    return(athlete_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/alpine-skiing/entries-by-event-alpine-team-event.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/biathlon/entries-by-event-men-s-4x7-5km-relay.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/biathlon/entries-by-event-women-s-4x6km-relay.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/biathlon/entries-by-event-2x6km-women--plus--2x7-5km-men-mixed-relay.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/bobsleigh/entries-by-event-2-man.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/bobsleigh/entries-by-event-4-man.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/bobsleigh/entries-by-event-women.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/cross-country-skiing/entries-by-event-men-s-team-sprint-free.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/cross-country-skiing/entries-by-event-men-s-4-x-10km-relay.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/cross-country-skiing/entries-by-event-ladies-team-sprint-free.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/cross-country-skiing/entries-by-event-ladies-4-x-5km-relay.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/figure-skating/entries-by-event-pair-skating.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/figure-skating/entries-by-event-ice-dance.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/figure-skating/entries-by-event-team-event.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/ice-hockey/entries-by-event-men.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/ice-hockey/entries-by-event-women.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/luge/entries-by-event-doubles.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/luge/entries-by-event-team-relay.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/nordic-combined/entries-by-event-team-gundersen-lh-4x5km.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/short-track-speed-skating/entries-by-event-men-s-5000m-relay.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/short-track-speed-skating/entries-by-event-ladies-3000m-relay.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/ski-jumping/entries-by-event-men-s-team.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/speed-skating/entries-by-event-men-s-team-pursuit.htm\n",
      "Possible team event? \t https://www.olympic.org/pyeongchang-2018/results/en/speed-skating/entries-by-event-ladies-team-pursuit.htm\n"
     ]
    }
   ],
   "source": [
    "# TODO: make rankings table for event\n",
    "# event, sport(id), athlete(id), placed, result\n",
    "team_events = []\n",
    "\n",
    "# TODO: get all athlete info (including teams!)\n",
    "\n",
    "# Keep athlete data in its own table\n",
    "athletes_info = []\n",
    "\n",
    "## go by each event \n",
    "for event in events_info:\n",
    "    # Use entries page to get list of athletes ranked\n",
    "    entries_page = event['page']\n",
    "    ranking_page = entries_page.replace('entries-by-event','medals-and-ranking')\n",
    "    ## Get document to be passed in for soup (better/cleaner practice)\n",
    "    request_ranking = requests.get(ranking_page)\n",
    "    text_ranking = request_ranking.text\n",
    "    soup_ranking = BeautifulSoup(text_ranking, 'html.parser')\n",
    "\n",
    "    # Get all entries in table\n",
    "    athlete_rank_table = soup_ranking.find_all('tr', {'class':['Res2', 'Res1']})\n",
    "    \n",
    "    # Do this for individual sports (need something different teams)\n",
    "    try:\n",
    "        for row in athlete_rank_table:\n",
    "            # All entry information in cols -> [medal info, rank, athlete info, result] \n",
    "            cols = row.find_all('td')\n",
    "            # skip the first column (just medal info)\n",
    "            # 2nd column only has rank (note that rank can be blank)\n",
    "            rank = cols[1].text.strip()\n",
    "\n",
    "            # 3rd colum is athlete data in divs\n",
    "            athlete_div = cols[2].div\n",
    "            # Get athlete id first (so we don't have to do work every time)\n",
    "            \n",
    "            athlete_dict = get_athlete_info(athlete_div)\n",
    "\n",
    "            # TODO: get result of event for each entry (may not be avail)\n",
    "\n",
    "            # Add athletes into event \n",
    "            # Check athlete doesn't already exist in athlete table by checking id\n",
    "            if athlete_dict['id'] in [athlete['id'] for athlete in athletes_info]:\n",
    "                continue\n",
    "            # Add in info\n",
    "            athletes_info.append(athlete_dict)\n",
    "\n",
    "    except:\n",
    "        print('Possible team event? \\t {}'.format(entries_page))\n",
    "        # Save this as a team event\n",
    "        team_events.append(event)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898\n",
      "24\n",
      "[{'birth_year': '1982', 'name': 'a', 'profile': 'https://www.olympic.org/pyeongchang-2018/results/en/alpine-skiing/athlete-profile-n3025445-aksel-lund-svindal.htm', 'country_id': 'NOR', 'id': '3025445', 'birth_month': '12', 'birth_day': '26', 'photo': 'https://www.olympic.org/pyeongchang-2018/results/resOWG2018/img/bios/photos/3025445.jpg'}, {'birth_year': '1985', 'name': 'kjetil jansrud', 'profile': 'https://www.olympic.org/pyeongchang-2018/results/en/alpine-skiing/athlete-profile-n3025444-kjetil-jansrud.htm', 'country_id': 'NOR', 'id': '3025444', 'birth_month': '08', 'birth_day': '28', 'photo': 'https://www.olympic.org/pyeongchang-2018/results/resOWG2018/img/bios/photos/3025444.jpg'}, {'birth_year': '1987', 'name': 'beat feuz', 'profile': 'https://www.olympic.org/pyeongchang-2018/results/en/alpine-skiing/athlete-profile-n3034495-beat-feuz.htm', 'country_id': 'SUI', 'id': '3034495', 'birth_month': '02', 'birth_day': '11', 'photo': 'https://www.olympic.org/pyeongchang-2018/results/resOWG2018/img/bios/photos/3034495.jpg'}, {'birth_year': '1989', 'name': 'dominik paris', 'profile': 'https://www.olympic.org/pyeongchang-2018/results/en/alpine-skiing/athlete-profile-n3027612-dominik-paris.htm', 'country_id': 'ITA', 'id': '3027612', 'birth_month': '04', 'birth_day': '14', 'photo': 'https://www.olympic.org/pyeongchang-2018/results/resOWG2018/img/bios/photos/3027612.jpg'}, {'birth_year': '1993', 'name': 'thomas dressen', 'profile': 'https://www.olympic.org/pyeongchang-2018/results/en/alpine-skiing/athlete-profile-n3030911-thomas-dressen.htm', 'country_id': 'GER', 'id': '3030911', 'birth_month': '11', 'birth_day': '22', 'photo': 'https://www.olympic.org/pyeongchang-2018/results/resOWG2018/img/bios/photos/3030911.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "print(len(athletes_info))\n",
    "print(len(team_events))\n",
    "\n",
    "# athletes_info[0]['name'] = 'a\n",
    "\n",
    "print(athletes_info[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get additional athlete info via her profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for athlete in athletes_info: \n",
    "    extra_info = get_athlete_profile_info(athlete['profile'])\n",
    "    # Save into athlete's dictionary\n",
    "    for k,v in extra_info.items():\n",
    "        athlete[k] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save sports data into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV file from list of sports dictionaries\n",
    "with open('sports.csv', 'w') as sports_csv:\n",
    "    writer = csv.writer(sports_csv)\n",
    "    \n",
    "    # Headers\n",
    "    headers = ['id', 'name', 'img', 'schedule']\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Get each dictionary assoc. with the sport\n",
    "    for sport in sports_info:\n",
    "        # Use only the headers (in order) to write row \n",
    "        row = [sport[key] for key in headers]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Country Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference page to list of all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_countries = 'https://www.olympic.org/pyeongchang-2018/results/en/general/nocs-list.htm'\n",
    "\n",
    "# Get document to be passed in for soup (better/cleaner practice)\n",
    "request_countries = requests.get(url_list_countries)\n",
    "text_countires = request_countries.text\n",
    "\n",
    "# Get all countries from main page\n",
    "soup_countries = BeautifulSoup(text_countires, 'html.parser')\n",
    "countries = soup_countries.find_all('div', class_='CountriesListItem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country pages, flags, IDs, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries of countries info \n",
    "countries_info = []\n",
    "\n",
    "# Iterate over countries and save info\n",
    "for country in countries:\n",
    "    # Country code gives an identifier of 3 character\n",
    "    country_id = country['attrcountrycode']\n",
    "\n",
    "    # Country web page\n",
    "    country_page_link = country.a['href']\n",
    "    match = re.search('\\/(noc-entries-([-\\w]+)\\.htm)$',country_page_link)\n",
    "    # group(1) form: noc-entries-country.htm\n",
    "    country_page = '{}{}general/{}'.format(dr_results, dr_connector, match.group(1))\n",
    "    \n",
    "    # Country full name\n",
    "    country_name = match.group(2) \n",
    "\n",
    "    # Flag image =>\n",
    "    country_flag = '{}resCOMMON/img/flags/{}.png'.format(dr_results,country_id)\n",
    "    \n",
    "    # Create a dictionary to be saved\n",
    "    country_dict = {'code_id':country_id, 'name':country_name, 'page':country_page, 'flag':country_flag}\n",
    "    countries_info.append(country_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "print(len(countries_info))\n",
    "\n",
    "\n",
    "for key, info in countries_info[0].items():\n",
    "    print(key, info)\n",
    "print()\n",
    "for key, info in countries_info[-1].items():\n",
    "    print(key, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save country data into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV file from list of countries dictionaries\n",
    "with open('countries.csv', 'w') as countries_csv:\n",
    "    writer = csv.writer(countries_csv)\n",
    "    \n",
    "    # Headers\n",
    "    headers = ['code_id', 'name', 'flag', 'page']\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Get each dictionary assoc. with the sport\n",
    "    for country in countries_info:\n",
    "        # Use only the headers (in order) to write row \n",
    "        row = [country[key] for key in headers]\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
